<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Graph Transformers | 吃萝卜不吐萝卜皮~</title><meta name="author" content="fortunato"><meta name="copyright" content="fortunato"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="一些关于transformer  cls：classification，用于下游的分类任务。CLS就是一个向量，只是不是某一个字的向量，是一个够代表整个文本的的语义特征向量，取出来就可以直接用于分类了。实际场景：问答（判断一个问题与一个答案是否匹配）、语句匹配（两句话是否表达同一个意思）等 BERT模型除了添加[CLS]符号并将对应的输出作为文本的语义表示，还对输入的两句话用一个[SEP]符">
<meta property="og:type" content="article">
<meta property="og:title" content="Graph Transformers">
<meta property="og:url" content="https://fortunato-all.github.io/posts/46224/index.html">
<meta property="og:site_name" content="吃萝卜不吐萝卜皮~">
<meta property="og:description" content="一些关于transformer  cls：classification，用于下游的分类任务。CLS就是一个向量，只是不是某一个字的向量，是一个够代表整个文本的的语义特征向量，取出来就可以直接用于分类了。实际场景：问答（判断一个问题与一个答案是否匹配）、语句匹配（两句话是否表达同一个意思）等 BERT模型除了添加[CLS]符号并将对应的输出作为文本的语义表示，还对输入的两句话用一个[SEP]符">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/%E5%A4%A7%E5%9B%BE.jpg">
<meta property="article:published_time" content="2023-03-29T05:27:28.000Z">
<meta property="article:modified_time" content="2023-05-07T01:02:52.851Z">
<meta property="article:author" content="fortunato">
<meta property="article:tag" content="transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/%E5%A4%A7%E5%9B%BE.jpg"><link rel="shortcut icon" href="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/论文阅读笔记/头像.jpg"><link rel="canonical" href="https://fortunato-all.github.io/posts/46224/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: fortunato","link":"链接: ","source":"来源: 吃萝卜不吐萝卜皮~","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#d7d1dd","bgDark":"#1f1f1f","position":"bottom-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Graph Transformers',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-07 09:02:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/footer.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/论文阅读笔记/头像.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-solid fa-book"></i><span> 书</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/lives/"><i class="fa-fw fa-solid fa-file-pen"></i><span> 随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">吃萝卜不吐萝卜皮~</a></span><div id="he-plugin-simple"></div><div id="none_space"></div><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-solid fa-book"></i><span> 书</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/lives/"><i class="fa-fw fa-solid fa-file-pen"></i><span> 随笔</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Graph Transformers</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-29T05:27:28.000Z" title="发表于 2023-03-29 13:27:28">2023-03-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-07T01:02:52.851Z" title="更新于 2023-05-07 09:02:52">2023-05-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>10分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Graph Transformers"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="一些关于transformer">一些关于transformer</h1>
<ol type="1">
<li><p>cls：classification，用于下游的分类任务。CLS就是一个向量，只是不是某一个字的向量，是一个够代表整个文本的的语义特征向量，取出来就可以直接用于分类了。实际场景：问答（判断一个问题与一个答案是否匹配）、语句匹配（两句话是否表达同一个意思）等</p></li>
<li><p>BERT模型除了添加[CLS]符号并将对应的输出作为文本的语义表示，还对输入的两句话用一个[SEP]符号作分割，并分别对两句话附加两个不同的文本向量以作区分，如下图所示。</p></li>
<li><p>RNN的两个明显问题：<img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/rnn.jpg" style="zoom:50%;" /></p>
<ol type="1">
<li><p>效率问题：需要逐个词进行处理，后一个词要等到前一个词的隐状态输出以后才能开始处理</p></li>
<li><p>如果传递距离过长还会有梯度消失、梯度爆炸和遗忘问题</p>
<p>LSTM、GRU的改进属于换汤不换药。</p></li>
</ol>
<p>为解决这些问题，设计的Transformer是一个N进N出的结构，每个Transformer单元相当于一层的RNN层，接收一整个句子所有词作为输入，然后为句子中的每个词都做出一个输出。但是与RNN不同的是，Transformer能够同时处理句子中的所有词，并且任意两个词之间的操作距离都是1，很好地解决了上面提到的RNN的效率问题和距离问题。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/transformer.jpg" style="zoom:50%;" /></p>
<p>decoder比encoder多了一共attention，用于接受encoder的输出：</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230331172600.png" style="zoom: 67%;" /></p>
<p>详细结构：</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230331172734.png" style="zoom:70%;" /></p>
<ul>
<li><p>encoder的输入包含两个，是一个序列的token embedding + positional
embedding</p></li>
<li><p>self-attention层：句子中的某个词对于本身的所有词做一次Attention，算出每个词对于这个词的权重，然后将这个词表示为所有词的加权和。</p>
<p>首先，每个词都要通过三个矩阵<span class="math inline">\(W_q\)</span>,
<span class="math inline">\(W_k\)</span>, <span
class="math inline">\(W_v\)</span>进行一次线性变化，一分为三，生成每个词自己的query,
key, vector三个向量。以一个词为中心进行Self
Attention时，都是用这个词的key向量与每个词的query向量做点积，再通过Softmax归一化出权重。通过这些权重算出所有词的vector的加权和，作为这个词的输出。（通过
query 和 key 的相似性程度来确定 value 的权重分布的方法被称为scaled
dot-product attention。）</p>
<p>self-attention的特点在于无视词之间的距离直接计算依赖关系，能够学习一个句子的内部结构，实现也较为简单并且可以并行计算。从一些论文中看到，
self-attention可以当成一个层和RNN,CNN,FNN等配合使用，成功应用于其他NLP任务。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230331173129.png" style="zoom:50%;" /></p>
<p>归一化之前需要通过除以向量的维度dk来进行标准化，所以最终Self
Attention用矩阵变换的方式可以表示为: <span class="math display">\[
Q=XW_Q\\
K=XW_K\\
V=XW_V\\
Attention(Q,K,V)=Softmax(\frac{QK^T}{\sqrt{d_k}})V
\]</span> 上文提到Encoder中的Self
Attention与Decoder中的有所不同，Encoder中的Q、K、V全部来自于上一层单元的输出，而Decoder只有Q来自于上一个Decoder单元的输出，K与V都来自于Encoder最后一层的输出。也就是说，Decoder是要通过当前状态与Encoder的输出算出权重后，将Encoder的编码加权得到下一层的状态。</p></li>
<li><p>Multi-head-attention：Multi-Head
Attention就是将上述的Attention做h遍，然后将h个输出进行concat得到最终的输出。这样做可以很好地提高算法的稳定性，在很多Attention相关的工作中都有相关的应用。Transformer的实现中，为了提高Multi-Head的效率，将W扩大了h倍，然后通过view(reshape)和transpose操作将相同词的不同head的k、q、v排列在一起进行同时计算，完成计算后再次通过reshape和transpose完成拼接，相当于对于所有的head进行了一个并行处理。</p></li>
<li><p>Masked-attention：Encoder要编码整个句子，所以每个词都要考虑上下文的关系。所以每个词在计算的过程中都是可以看到句子中所有的词的。但是Decoder与Seq2Seq中的解码器类似，每个词都只能看到前面词的状态，所以是一个单向的Self-Attention结构。Masked
Attention的实现也非常简单，只要在普通的Self
Attention的Softmax步骤之前，与(&amp;)上一个下三角矩阵M就好了 <span
class="math display">\[
Attention(Q,K,V)=Softmax(\frac{QK^T \odot M}{\sqrt{d_k}})V
\]</span></p></li>
<li><p>Position-wise Feed Forward
Networks：Encoder中和Decoder中经过Attention之后输出的n个向量（这里n是词的个数）都分别的输入到一个全连接层中，完成一个逐个位置的前馈网络。</p>
<ul>
<li>FFN是两层全连接。这里使用FFN层的原因是：为了使用非线性函数来拟合数据。如果说只是为了非线性拟合的话，其实只用到第一层就可以了，但是这里为什么要用两层全连接呢，是因为第一层的全连接层计算后，其维度是(batch_size,
seq_len,
dff)（其中dff是超参数的一种，设置为2048），而使用第二层全连接层是为了进行维度变换，将dff转换为初始的d_model(512)维。</li>
</ul>
<p><span class="math display">\[
FFN(x)=max(0,xW_1+b_1)W_2+b_2
\]</span></p></li>
<li><p>Add &amp;
Norm：是一个残差网络，将一层的输入与其标准化后的输出进行相加即可。Transformer中每一个Self
Attention层与FFN层后面都会连一个Add &amp;
Norm层。该层是为了对attention层的输出进行分布归一化，转换成均值为0方差为1的正态分布。cv中经常会用的是batchNorm，是对一个batchsize中的样本进行一次归一化，而layernorm则是对一层进行一次归一化，二者的作用是一样的，只是针对的维度不同，一般来说batchnorm的输入维度是(batch_size,
seq_len,
embedding)，针对的是batch_size层进行处理，而layernorm则是对seq_len进行处理（即batchnorm是对一批样本中进行归一化，而layernorm是对每一个样本进行一次归一化）。使用ln而不是bn的原因是因为输入序列的长度问题，每一个序列的长度不同，虽然会经过padding处理，但是padding的0值其实是无用信息，实际上有用的信息还是序列信息，而不同序列的长度不同，所以这里不能使用bn一概而论。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230331175224.png" style="zoom:50%;" /></p></li>
<li><p>Positional
Encoding：Transformer中句子里的所有词都被同等的看待，所以词之间就没有了先后关系，很可能会带上和词袋模型相同的不足。因此，需要给每个输入的词向量叠加一个固定的向量来表示它的位置
<span class="math display">\[
PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\\
PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})
\]</span>
pos是词在句子中的位置，i是词向量中第i位，即将每个词的词向量为一行进行叠加，然后针对每一列都叠加上一个相位不同或波长逐渐增大的波，以此来唯一区分位置。</p></li>
</ul></li>
<li><p>GPT(Generative
Pre-Training)，是OpenAI在2018年提出的模型，利用Transformer模型来解决各种自然语言问题，例如分类、推理、问答、相似度等应用的模型。GPT采用了Pre-training
+
Fine-tuning的训练模式，使得大量无标记的数据得以利用，大大提高了这些问题的效果。</p>
<ul>
<li>Decoder Block中使用的是Masked
Self-Attention，即句子中的每个词，都只能对包括自己在内的前面所有词进行Attention，这就是单向Transformer。GPT使用的Transformer结构就是将Encoder中的Self-Attention替换成了Masked
Self-Attention</li>
</ul></li>
<li><p>关系归纳偏置（relational inductive biases）</p></li>
<li><p>讲解一些编码：https://blog.csdn.net/zjc910997316/article/details/121524624</p></li>
<li><p>https://blog.csdn.net/qq_38253797/article/details/127620115</p></li>
<li><p>https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&amp;mid=2247493785&amp;idx=3&amp;sn=5730ed0d277e049f31880a0ceba7629f&amp;chksm=ebb7d04ddcc0595bd9b38659832f8c8b681d374fe29108337e491a3c6d60b3a4fa873939294b&amp;scene=27</p></li>
</ol>
<h1
id="graph-formers-gnn-nested-transformers-for-representation-learning-on-textual-graph">Graph-Formers:
GNN-nested Transformers for Representation Learning on Textual
Graph</h1>
<p><em>from NIPS 2021, <a
target="_blank" rel="noopener" href="https://github.com/microsoft/GraphFormers">code</a></em></p>
<h3 id="motivation">Motivation：</h3>
<p>文本图上的表示学习是基于<strong>单个的文本特征</strong>和<strong>邻域信息</strong>为节点生成低维embeddings。现有的方法主要依赖于cascaded
model architecture：节点的textural
features首先由语言模型独立编码；textural
embeddings再通过GNN进行聚合。但是由于对textural
features的独立建模，上述体系结构受到了限制。</p>
<p>本文提出的GraphFormers中，GNN组件按层嵌套在the transformer blocks of
language models旁边，使用该框架后，<strong>text
encoding</strong>和<strong>graph aggregation</strong> are fused into and
iterative workflow，从全局的角度准确地理解每个节点的语义(semantic)。</p>
<p>另外，还是用了一个progressive learning
strategy，通过对操作数据(manipulated data)和原始数据(original
data)进行连续(successively)训练，增强模型对图上信息的整合能力。</p>
<h3 id="intro">Intro：</h3>
<p>目前的主流方法是Pre-trained Language
Representation(PLM，例如BERT，获得文本的底层语义)结合GNN(聚合邻域信息，获得more
informative的embeddings)。这种组合方式叫做Cascaded
Transformers-GNN，因为transformers部署在GNN前面，<font color="#FF0000">
</font> 。但是，考虑到linked
nodes是相互关联的，<strong>在生成embedding时，其底层语义可以相互增强</strong>。例如，给定一个节点“notes
on transformers”和他的邻居的“tutorials on machine
translation”，通过参考整个上下文，这里的“transformers”可以被解释为一个机器学习模型，而不是一个电子设备变压器。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230311204736.png" alt="Cascaded Transformers-GNN：text embeddings are independently generated by language models and aggregated by rear-mounted GNNs"  /></p>
<p>在本文中，文本编码(transformerer
layers)和图聚合(GNN)迭代进行，在每个迭代后，linked
nodes在layerwise的GNN组件中相互交换信息；因此，<font color="#FF0000">每个节点都将被其邻域信息增强（在这里可以使用异质性？）</font>。然后transformer在增强的节点特征上work，这个节点特征可以为下一次迭代生成信息更丰富的节点表示。与级联架构相比，GraphFormers图上的cross-node
information进行了更充分的利用，大大提高了表示质量。考虑到分层的GNN组件只涉及简单和有效的<font color="#FF0000">multi-head
attention</font>，GraphFormers保持了与现有的级联模型相当的运行成本。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/Snipaste_2023-03-11_20-52-33.png" alt="GNN-nested Transformers: the text encoding and graph aggregation are iteratively performed with the layerwise GNNs and Transformers(TRM)." style="zoom:90%;" /></p>
<p>训练过程中：</p>
<h3 id="method">Method</h3>
<p>每个节点x都是一个text，节点x及其相邻节点<span
class="math inline">\(N_x\)</span>记为<span
class="math inline">\(G_x\)</span>。模型基于节点x的文本特征和他的邻域信息来学习嵌入。生成的嵌入被期望捕获节点之间的关系，<font color="#FF0000">即基于嵌入的相似度准确地预测两个节点是否是而进行连接的。</font></p>
<p>关于<strong>token embedding</strong>，</p>
<h4 id="model-simplification">model simplification</h4>
<p>训练任务是链路预测</p>
<h1
id="graphtrans-representing-long-range-context-for-graph-neural-networks-with-global-attention">GraphTrans:
Representing Long-Range Context for Graph Neural Networks with Global
Attention</h1>
<p>graph classification task（text-classification）</p>
<h3 id="cls">CLS：</h3>
<p>将图输入GNN获得图中每个节点的向量表示（让节点的向量表示获取位置信息），之后将每个节点的向量表示输入标准的Transformer（将自然语言处理中的CLS作为一种readout机制引入图分类）</p>
<p>在节点序列的首位置加入一个CLS节点（因为使用的Transformer不带positional
encoding，所以CLS的位置可以随意选取），之后使用经过Transformer的CLS表示进行图分类任务。</p>
<p>实质上，CLS readout可以做是virtual node的generalization或者deep
version.（This special-token readout mechanism may be viewed as a
generalization or a “deep” version of a virtual node readout.但是virtual
node method不允许学习图节点之间的成对关系，除了在虚拟节点的嵌入内）</p>
<h1 id="graphgps-recipe-for-a-general-powerful-scalable">GraphGPS:
Recipe for a General, Powerful, Scalable</h1>
<h3
id="对现有的pepositional-emcodings和sestructural-encodings进行分类">对现有的PE(positional
emcodings)和SE(structural encodings)进行分类</h3>
<p>各自作用：PE gives a notion of <strong>distance</strong>, while SE
gives a notion of <strong>structural similarity</strong>.</p>
<p>One can always infer certain notions of distance from large
structures, or certain notions of structure from short distances, but
this is not a trivial task, and the objective of providing PE and SE
remains distinct.</p>
<p>PE是为了提供图中给定节点在空间中的位置的概念。因此，当在图或子图中两个节点彼此接近时，它们的PE也应该接近。一种常见的方法是计算每对节点或其特征向量之间的pair-wise
distance，但这与Transformer器不兼容，因为它需要实现full attention
matrix。相反，我们希望PE是节点或者边的特征，因此，一个更好的拟合解是使用图的拉普拉斯矩阵的特征向量或它们的梯度。</p>
<p>SE旨在提供图或子图结构的embedding，以提高GNN的expressivity and the
generalizability。因此，当两个节点共享相似的子图时，或者当两个图相似时，它们的SE也应该很接近。简单的方法是将图中的pre-defined
patterns识别为一个热编码，但它们需要对图的专家知识。</p>
<p>这些编码如何增加MPNNs的表达</p>
<p>参考链接：</p>
<p>https://blog.csdn.net/yeen123/article/details/125104680</p>
<p>https://zhuanlan.zhihu.com/p/604450283</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://fortunato-all.github.io">fortunato</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://fortunato-all.github.io/posts/46224/">https://fortunato-all.github.io/posts/46224/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://fortunato-all.github.io" target="_blank">吃萝卜不吐萝卜皮~</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/transformer/">transformer</a></div><div class="post_share"><div class="social-share" data-image="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/52924/"><img class="prev-cover" src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230306105851.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">动态图异常检测——HOG-GCN</div></div></a></div><div class="next-post pull-right"><a href="/posts/47450/"><img class="next-cover" src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">图神经网络</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/论文阅读笔记/头像.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">fortunato</div><div class="author-info__description">记一忘三二</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/fortunato-all"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/fortunato-all" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%85%B3%E4%BA%8Etransformer"><span class="toc-text">一些关于transformer</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#graph-formers-gnn-nested-transformers-for-representation-learning-on-textual-graph"><span class="toc-text">Graph-Formers:
GNN-nested Transformers for Representation Learning on Textual
Graph</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation"><span class="toc-text">Motivation：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#intro"><span class="toc-text">Intro：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#method"><span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#model-simplification"><span class="toc-text">model simplification</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#graphtrans-representing-long-range-context-for-graph-neural-networks-with-global-attention"><span class="toc-text">GraphTrans:
Representing Long-Range Context for Graph Neural Networks with Global
Attention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cls"><span class="toc-text">CLS：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#graphgps-recipe-for-a-general-powerful-scalable"><span class="toc-text">GraphGPS:
Recipe for a General, Powerful, Scalable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E7%8E%B0%E6%9C%89%E7%9A%84pepositional-emcodings%E5%92%8Csestructural-encodings%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB"><span class="toc-text">对现有的PE(positional
emcodings)和SE(structural encodings)进行分类</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/47450/" title="图神经网络"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图神经网络"/></a><div class="content"><a class="title" href="/posts/47450/" title="图神经网络">图神经网络</a><time datetime="2023-04-21T00:39:04.000Z" title="发表于 2023-04-21 08:39:04">2023-04-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/46224/" title="Graph Transformers"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Graph Transformers"/></a><div class="content"><a class="title" href="/posts/46224/" title="Graph Transformers">Graph Transformers</a><time datetime="2023-03-29T05:27:28.000Z" title="发表于 2023-03-29 13:27:28">2023-03-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/52924/" title="动态图异常检测——HOG-GCN"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/hetero/20230306105851.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="动态图异常检测——HOG-GCN"/></a><div class="content"><a class="title" href="/posts/52924/" title="动态图异常检测——HOG-GCN">动态图异常检测——HOG-GCN</a><time datetime="2023-03-05T02:08:22.000Z" title="发表于 2023-03-05 10:08:22">2023-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/62968/" title="动态图异常检测数据集，及GearSage代码详解"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="动态图异常检测数据集，及GearSage代码详解"/></a><div class="content"><a class="title" href="/posts/62968/" title="动态图异常检测数据集，及GearSage代码详解">动态图异常检测数据集，及GearSage代码详解</a><time datetime="2023-02-21T01:56:25.000Z" title="发表于 2023-02-21 09:56:25">2023-02-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/59918/" title="扩散模型"><img src="https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/大图.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="扩散模型"/></a><div class="content"><a class="title" href="/posts/59918/" title="扩散模型">扩散模型</a><time datetime="2023-02-19T09:34:14.000Z" title="发表于 2023-02-19 17:34:14">2023-02-19</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://testingcf.jsdelivr.net/gh/fortunato-all/tuchuang/主页背景.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By fortunato</div><div class="footer_custom_text">相逢的人会再相逢</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadWaline () {
  function insertCSS () {
    const link = document.createElement("link")
    link.rel = "stylesheet"
    link.href = "https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css"
    document.head.appendChild(link)
  }

  function initWaline () {
    const waline = Waline.init(Object.assign({
      el: '#waline-wrap',
      serverURL: 'https://waline-20enl8ipe-fortunato-all.vercel.app/',
      pageview: false,
      dark: 'html[data-theme="dark"]',
      path: window.location.pathname,
      comment: false,
    }, null))
  }

  if (typeof Waline === 'function') initWaline()
  else {
    insertCSS()
    getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js').then(initWaline)
  }
}

if ('Waline' === 'Waline' || !true) {
  if (true) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
  else setTimeout(loadWaline, 0)
} else {
  function loadOtherComment () {
    loadWaline()
  }
}</script></div><script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script src="/js/weather.js"></script><script src="https://cdn.jsdelivr.net/gh/xiabo2/CDN@latest/fishes.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>